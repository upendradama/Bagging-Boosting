{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "\n",
    "### Problem Statement -\n",
    "\n",
    "        - Divide the data (WBCD) into training and test datasets and create a Boosting Model to \n",
    "          classify 'Class Variable'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  87139402         B        12.32         12.39           78.85      464.1   \n",
       "1   8910251         B        10.60         18.95           69.28      346.4   \n",
       "2    905520         B        11.04         16.83           70.92      373.2   \n",
       "3    868871         B        11.28         13.39           73.00      384.8   \n",
       "4   9012568         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  ...  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700  ...   \n",
       "1          0.09688           0.11470         0.06387      0.02642  ...   \n",
       "2          0.10770           0.07804         0.03046      0.02480  ...   \n",
       "3          0.11640           0.11360         0.04635      0.04796  ...   \n",
       "4          0.07963           0.06934         0.03393      0.02657  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         13.50          15.64            86.97       549.1            0.1385   \n",
       "1         11.88          22.94            78.28       424.8            0.1213   \n",
       "2         12.41          26.44            79.93       471.4            0.1369   \n",
       "3         11.92          15.77            76.53       434.0            0.1367   \n",
       "4         16.20          15.73           104.50       819.1            0.1126   \n",
       "\n",
       "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
       "0             0.1266          0.12420       0.09391          0.2827   \n",
       "1             0.2515          0.19160       0.07926          0.2940   \n",
       "2             0.1482          0.10670       0.07431          0.2998   \n",
       "3             0.1822          0.08669       0.08611          0.2102   \n",
       "4             0.1737          0.13620       0.08178          0.2487   \n",
       "\n",
       "   dimension_worst  \n",
       "0          0.06771  \n",
       "1          0.07587  \n",
       "2          0.07881  \n",
       "3          0.06784  \n",
       "4          0.06766  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv (\"~/desktop/Digi 360/Module 20/Datasets-9/wbcd.csv\",encoding='mac_roman')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'points_mean', 'symmetry_mean', 'dimension_mean', 'radius_se',\n",
       "       'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'points_se', 'symmetry_se',\n",
       "       'dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst',\n",
       "       'area_worst', 'smoothness_worst', 'compactness_worst',\n",
       "       'concavity_worst', 'points_worst', 'symmetry_worst', 'dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "id                   569 non-null int64\n",
      "diagnosis            569 non-null object\n",
      "radius_mean          569 non-null float64\n",
      "texture_mean         569 non-null float64\n",
      "perimeter_mean       569 non-null float64\n",
      "area_mean            569 non-null float64\n",
      "smoothness_mean      569 non-null float64\n",
      "compactness_mean     569 non-null float64\n",
      "concavity_mean       569 non-null float64\n",
      "points_mean          569 non-null float64\n",
      "symmetry_mean        569 non-null float64\n",
      "dimension_mean       569 non-null float64\n",
      "radius_se            569 non-null float64\n",
      "texture_se           569 non-null float64\n",
      "perimeter_se         569 non-null float64\n",
      "area_se              569 non-null float64\n",
      "smoothness_se        569 non-null float64\n",
      "compactness_se       569 non-null float64\n",
      "concavity_se         569 non-null float64\n",
      "points_se            569 non-null float64\n",
      "symmetry_se          569 non-null float64\n",
      "dimension_se         569 non-null float64\n",
      "radius_worst         569 non-null float64\n",
      "texture_worst        569 non-null float64\n",
      "perimeter_worst      569 non-null float64\n",
      "area_worst           569 non-null float64\n",
      "smoothness_worst     569 non-null float64\n",
      "compactness_worst    569 non-null float64\n",
      "concavity_worst      569 non-null float64\n",
      "points_worst         569 non-null float64\n",
      "symmetry_worst       569 non-null float64\n",
      "dimension_worst      569 non-null float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "diagnosis            0\n",
       "radius_mean          0\n",
       "texture_mean         0\n",
       "perimeter_mean       0\n",
       "area_mean            0\n",
       "smoothness_mean      0\n",
       "compactness_mean     0\n",
       "concavity_mean       0\n",
       "points_mean          0\n",
       "symmetry_mean        0\n",
       "dimension_mean       0\n",
       "radius_se            0\n",
       "texture_se           0\n",
       "perimeter_se         0\n",
       "area_se              0\n",
       "smoothness_se        0\n",
       "compactness_se       0\n",
       "concavity_se         0\n",
       "points_se            0\n",
       "symmetry_se          0\n",
       "dimension_se         0\n",
       "radius_worst         0\n",
       "texture_worst        0\n",
       "perimeter_worst      0\n",
       "area_worst           0\n",
       "smoothness_worst     0\n",
       "compactness_worst    0\n",
       "concavity_worst      0\n",
       "points_worst         0\n",
       "symmetry_worst       0\n",
       "dimension_worst      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         B        12.32         12.39           78.85      464.1   \n",
       "1         B        10.60         18.95           69.28      346.4   \n",
       "2         B        11.04         16.83           70.92      373.2   \n",
       "3         B        11.28         13.39           73.00      384.8   \n",
       "4         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700   \n",
       "1          0.09688           0.11470         0.06387      0.02642   \n",
       "2          0.10770           0.07804         0.03046      0.02480   \n",
       "3          0.11640           0.11360         0.04635      0.04796   \n",
       "4          0.07963           0.06934         0.03393      0.02657   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.1959  ...         13.50          15.64            86.97   \n",
       "1         0.1922  ...         11.88          22.94            78.28   \n",
       "2         0.1714  ...         12.41          26.44            79.93   \n",
       "3         0.1771  ...         11.92          15.77            76.53   \n",
       "4         0.1721  ...         16.20          15.73           104.50   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       549.1            0.1385             0.1266          0.12420   \n",
       "1       424.8            0.1213             0.2515          0.19160   \n",
       "2       471.4            0.1369             0.1482          0.10670   \n",
       "3       434.0            0.1367             0.1822          0.08669   \n",
       "4       819.1            0.1126             0.1737          0.13620   \n",
       "\n",
       "   points_worst  symmetry_worst  dimension_worst  \n",
       "0       0.09391          0.2827          0.06771  \n",
       "1       0.07926          0.2940          0.07587  \n",
       "2       0.07431          0.2998          0.07881  \n",
       "3       0.08611          0.2102          0.06784  \n",
       "4       0.08178          0.2487          0.06766  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping ID column\n",
    "\n",
    "df = df.drop('id', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faba91c4e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(6, 3))\n",
    "sns.countplot(x=\"diagnosis\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        12.32         12.39           78.85      464.1          0.10280   \n",
       "1        10.60         18.95           69.28      346.4          0.09688   \n",
       "2        11.04         16.83           70.92      373.2          0.10770   \n",
       "3        11.28         13.39           73.00      384.8          0.11640   \n",
       "4        15.19         13.21           97.65      711.8          0.07963   \n",
       "\n",
       "   compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           0.06981         0.03987      0.03700         0.1959   \n",
       "1           0.11470         0.06387      0.02642         0.1922   \n",
       "2           0.07804         0.03046      0.02480         0.1714   \n",
       "3           0.11360         0.04635      0.04796         0.1771   \n",
       "4           0.06934         0.03393      0.02657         0.1721   \n",
       "\n",
       "   dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.05955  ...         13.50          15.64            86.97   \n",
       "1         0.06491  ...         11.88          22.94            78.28   \n",
       "2         0.06340  ...         12.41          26.44            79.93   \n",
       "3         0.06072  ...         11.92          15.77            76.53   \n",
       "4         0.05544  ...         16.20          15.73           104.50   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       549.1            0.1385             0.1266          0.12420   \n",
       "1       424.8            0.1213             0.2515          0.19160   \n",
       "2       471.4            0.1369             0.1482          0.10670   \n",
       "3       434.0            0.1367             0.1822          0.08669   \n",
       "4       819.1            0.1126             0.1737          0.13620   \n",
       "\n",
       "   points_worst  symmetry_worst  dimension_worst  \n",
       "0       0.09391          0.2827          0.06771  \n",
       "1       0.07926          0.2940          0.07587  \n",
       "2       0.07431          0.2998          0.07881  \n",
       "3       0.08611          0.2102          0.06784  \n",
       "4       0.08178          0.2487          0.06766  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X = df.iloc[:,1:31]\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    B\n",
       "1    B\n",
       "2    B\n",
       "3    B\n",
       "4    B\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = df.iloc[:,0]\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>16.26</td>\n",
       "      <td>21.88</td>\n",
       "      <td>107.50</td>\n",
       "      <td>826.8</td>\n",
       "      <td>0.11650</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.17990</td>\n",
       "      <td>0.07981</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.06532</td>\n",
       "      <td>...</td>\n",
       "      <td>17.73</td>\n",
       "      <td>25.21</td>\n",
       "      <td>113.70</td>\n",
       "      <td>975.2</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.07953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>17.06</td>\n",
       "      <td>21.00</td>\n",
       "      <td>111.80</td>\n",
       "      <td>918.6</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.15080</td>\n",
       "      <td>0.09934</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.06071</td>\n",
       "      <td>...</td>\n",
       "      <td>20.99</td>\n",
       "      <td>33.15</td>\n",
       "      <td>143.20</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.2053</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>0.2623</td>\n",
       "      <td>0.07599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>10.97</td>\n",
       "      <td>17.20</td>\n",
       "      <td>71.73</td>\n",
       "      <td>371.5</td>\n",
       "      <td>0.08915</td>\n",
       "      <td>0.1113</td>\n",
       "      <td>0.09457</td>\n",
       "      <td>0.03613</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.06640</td>\n",
       "      <td>...</td>\n",
       "      <td>12.36</td>\n",
       "      <td>26.87</td>\n",
       "      <td>90.14</td>\n",
       "      <td>476.4</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.4082</td>\n",
       "      <td>0.4779</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.09532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>25.73</td>\n",
       "      <td>17.46</td>\n",
       "      <td>174.20</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.11490</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.33680</td>\n",
       "      <td>0.19130</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>33.13</td>\n",
       "      <td>23.58</td>\n",
       "      <td>229.30</td>\n",
       "      <td>3234.0</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.08815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>15.34</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.07032</td>\n",
       "      <td>...</td>\n",
       "      <td>18.07</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>0.2393</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "342        16.26         21.88          107.50      826.8          0.11650   \n",
       "138        17.06         21.00          111.80      918.6          0.11190   \n",
       "434        10.97         17.20           71.73      371.5          0.08915   \n",
       "47         25.73         17.46          174.20     2010.0          0.11490   \n",
       "64         15.34         14.26          102.50      704.4          0.10730   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "342            0.1283         0.17990      0.07981         0.1869   \n",
       "138            0.1056         0.15080      0.09934         0.1727   \n",
       "434            0.1113         0.09457      0.03613         0.1489   \n",
       "47             0.2363         0.33680      0.19130         0.1956   \n",
       "64             0.2135         0.20770      0.09756         0.2521   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "342         0.06532  ...         17.73          25.21           113.70   \n",
       "138         0.06071  ...         20.99          33.15           143.20   \n",
       "434         0.06640  ...         12.36          26.87            90.14   \n",
       "47          0.06121  ...         33.13          23.58           229.30   \n",
       "64          0.07032  ...         18.07          19.08           125.10   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "342       975.2            0.1426             0.2116           0.3344   \n",
       "138      1362.0            0.1449             0.2053           0.3920   \n",
       "434       476.4            0.1391             0.4082           0.4779   \n",
       "47       3234.0            0.1530             0.5937           0.6451   \n",
       "64        980.9            0.1390             0.5954           0.6305   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "342        0.1047          0.2736          0.07953  \n",
       "138        0.1827          0.2623          0.07599  \n",
       "434        0.1555          0.2540          0.09532  \n",
       "47         0.2756          0.3690          0.08815  \n",
       "64         0.2393          0.4667          0.09946  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342    M\n",
       "138    M\n",
       "434    B\n",
       "47     M\n",
       "64     M\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the score on train data\n",
    "dt.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9122807017543859"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the score on test data\n",
    "dt.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our model is overfitting here because train score is 100% and test score is 92%. Let's go for ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding score for test Data\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9956043956043956"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding score for train Data\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still we can see overfitting so let's go for Adaboosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada boosting \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# adaboost classifier with max 600 decision trees of depth=2\n",
    "# learning_rate/shrinkage=1.5\n",
    "\n",
    "# base estimator\n",
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# adaboost with the tree as base estimator\n",
    "adaboost_model_1 = AdaBoostClassifier(\n",
    "    base_estimator=dt,\n",
    "    n_estimators=600,\n",
    "    learning_rate=1.5,\n",
    "    algorithm=\"SAMME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=None,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1.5, n_estimators=600, random_state=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26894142, 0.73105858],\n",
       "       [0.73105858, 0.26894142],\n",
       "       [0.26894142, 0.73105858],\n",
       "       [0.26894142, 0.73105858],\n",
       "       [0.73105858, 0.26894142],\n",
       "       [0.26894142, 0.73105858],\n",
       "       [0.73105858, 0.26894142],\n",
       "       [0.73105858, 0.26894142],\n",
       "       [0.26894142, 0.73105858],\n",
       "       [0.73105858, 0.26894142]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions\n",
    "# the second column represents the probability of a click resulting in a download\n",
    "predictions = adaboost_model_1.predict_proba(X_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9301948051948051"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics: AUC\n",
    "metrics.roc_auc_score(y_test, predictions[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "param_grid = {\"base_estimator__max_depth\" : [2, 5],\n",
    "              \"n_estimators\": [200, 400, 600]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base estimator\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# adaboost with the tree as base estimator\n",
    "# learning rate is arbitrarily set to 0.6, we'll discuss learning_rate below\n",
    "ABC = AdaBoostClassifier(\n",
    "    base_estimator=dt,\n",
    "    learning_rate=0.6,\n",
    "    algorithm=\"SAMME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run grid search\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "folds = 3\n",
    "grid_search_ABC = GridSearchCV(ABC, \n",
    "                               cv = folds,\n",
    "                               param_grid=param_grid, \n",
    "                               scoring = 'roc_auc', \n",
    "                               return_train_score=True,                         \n",
    "                               verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME',\n",
       "                                          base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                min_samples_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                presort=False,\n",
       "                                                                                random_state=None,\n",
       "                                                                                splitter='best'),\n",
       "                                          learning_rate=0.6, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'base_estimator__max_depth': [2, 5],\n",
       "                         'n_estimators': [200, 400, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit \n",
    "grid_search_ABC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_base_estimator__max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.540558</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 2, 'n_estimators...</td>\n",
       "      <td>0.991443</td>\n",
       "      <td>0.995908</td>\n",
       "      <td>0.994925</td>\n",
       "      <td>0.994090</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.071370</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.049327</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>{'base_estimator__max_depth': 2, 'n_estimators...</td>\n",
       "      <td>0.990885</td>\n",
       "      <td>0.996280</td>\n",
       "      <td>0.994925</td>\n",
       "      <td>0.994028</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.597537</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.074385</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>2</td>\n",
       "      <td>600</td>\n",
       "      <td>{'base_estimator__max_depth': 2, 'n_estimators...</td>\n",
       "      <td>0.991071</td>\n",
       "      <td>0.996652</td>\n",
       "      <td>0.995113</td>\n",
       "      <td>0.994277</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'n_estimators...</td>\n",
       "      <td>0.981213</td>\n",
       "      <td>0.988467</td>\n",
       "      <td>0.985526</td>\n",
       "      <td>0.985068</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'n_estimators...</td>\n",
       "      <td>0.985398</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.984868</td>\n",
       "      <td>0.985813</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "      <td>{'base_estimator__max_depth': 5, 'n_estimators...</td>\n",
       "      <td>0.976097</td>\n",
       "      <td>0.983910</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.982211</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.540558      0.007982         0.028935        0.003707   \n",
       "1       1.071370      0.010160         0.049327        0.000775   \n",
       "2       1.597537      0.002448         0.074385        0.001579   \n",
       "3       0.021897      0.000709         0.002791        0.000043   \n",
       "4       0.021525      0.000262         0.002863        0.000076   \n",
       "5       0.022474      0.001972         0.002838        0.000053   \n",
       "\n",
       "  param_base_estimator__max_depth param_n_estimators  \\\n",
       "0                               2                200   \n",
       "1                               2                400   \n",
       "2                               2                600   \n",
       "3                               5                200   \n",
       "4                               5                400   \n",
       "5                               5                600   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'base_estimator__max_depth': 2, 'n_estimators...           0.991443   \n",
       "1  {'base_estimator__max_depth': 2, 'n_estimators...           0.990885   \n",
       "2  {'base_estimator__max_depth': 2, 'n_estimators...           0.991071   \n",
       "3  {'base_estimator__max_depth': 5, 'n_estimators...           0.981213   \n",
       "4  {'base_estimator__max_depth': 5, 'n_estimators...           0.985398   \n",
       "5  {'base_estimator__max_depth': 5, 'n_estimators...           0.976097   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.995908           0.994925         0.994090        0.001917   \n",
       "1           0.996280           0.994925         0.994028        0.002293   \n",
       "2           0.996652           0.995113         0.994277        0.002356   \n",
       "3           0.988467           0.985526         0.985068        0.002982   \n",
       "4           0.987165           0.984868         0.985813        0.000982   \n",
       "5           0.983910           0.986654         0.982211        0.004472   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                2                 1.0                 1.0   \n",
       "1                3                 1.0                 1.0   \n",
       "2                1                 1.0                 1.0   \n",
       "3                5                 1.0                 1.0   \n",
       "4                4                 1.0                 1.0   \n",
       "5                6                 1.0                 1.0   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0                 1.0               1.0              0.0  \n",
       "1                 1.0               1.0              0.0  \n",
       "2                 1.0               1.0              0.0  \n",
       "3                 1.0               1.0              0.0  \n",
       "4                 1.0               1.0              0.0  \n",
       "5                 1.0               1.0              0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search_ABC.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting AUC with hyperparameter combinations\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "for n, depth in enumerate(param_grid['base_estimator__max_depth']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(1,3, n+1)\n",
    "    depth_df = cv_results[cv_results['param_base_estimator__max_depth']==depth]\n",
    "\n",
    "    plt.plot(depth_df[\"param_n_estimators\"], depth_df[\"mean_test_score\"])\n",
    "    plt.plot(depth_df[\"param_n_estimators\"], depth_df[\"mean_train_score\"])\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(\"max_depth={0}\".format(depth))\n",
    "    plt.ylim([0.60, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that:\n",
    "\n",
    "The ensemble with max_depth=5 is clearly overfitting (training auc is almost 1, while the test score is much lower)\n",
    "At max_depth=2, the model performs slightly better (approx 98% AUC) with a higher test score\n",
    "\n",
    "Thus, we should go ahead with max_depth=2 and n_estimators=200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=2,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.6, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model performance on test data with chosen hyperparameters\n",
    "\n",
    "# base estimator\n",
    "tree = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# adaboost with the tree as base estimator\n",
    "# learning rate is arbitrarily set, we'll discuss learning_rate below\n",
    "ABC = AdaBoostClassifier(\n",
    "    base_estimator=tree,\n",
    "    learning_rate=0.6,\n",
    "    n_estimators=200,\n",
    "    algorithm=\"SAMME\")\n",
    "\n",
    "ABC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52000198, 0.47999802],\n",
       "       [0.51023909, 0.48976091],\n",
       "       [0.43849286, 0.56150714],\n",
       "       [0.38661523, 0.61338477],\n",
       "       [0.63762326, 0.36237674],\n",
       "       [0.52608206, 0.47391794],\n",
       "       [0.61343745, 0.38656255],\n",
       "       [0.60008626, 0.39991374],\n",
       "       [0.39434034, 0.60565966],\n",
       "       [0.62256009, 0.37743991]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test data\n",
    "predictions = ABC.predict_proba(X_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9896103896103896"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc auc\n",
    "metrics.roc_auc_score(y_test, predictions[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on training data with default hyperparameters\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6572901e-01, 7.3427099e-01],\n",
       "       [9.4488502e-01, 5.5114970e-02],\n",
       "       [4.0281475e-02, 9.5971853e-01],\n",
       "       [2.6363134e-04, 9.9973637e-01],\n",
       "       [9.9976140e-01, 2.3858515e-04],\n",
       "       [4.1526252e-01, 5.8473748e-01],\n",
       "       [9.9953270e-01, 4.6730309e-04],\n",
       "       [9.9977183e-01, 2.2817185e-04],\n",
       "       [5.1581860e-04, 9.9948418e-01],\n",
       "       [9.9981755e-01, 1.8242068e-04]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "# use predict_proba since we need probabilities to compute auc\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 98.80%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "roc = metrics.roc_auc_score(y_test, y_pred[:, 1])\n",
    "print(\"AUC: %.2f%%\" % (roc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with XGBoost\n",
    "\n",
    "# creating a KFold object \n",
    "folds = 3\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=2, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints...\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='binary:logistic',\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.2, 0.6],\n",
       "                         'subsample': [0.3, 0.6, 0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.3}</td>\n",
       "      <td>0.993118</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.993045</td>\n",
       "      <td>0.991913</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.046634</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.6}</td>\n",
       "      <td>0.992746</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.992293</td>\n",
       "      <td>0.993030</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.9}</td>\n",
       "      <td>0.992374</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.990226</td>\n",
       "      <td>0.991599</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030735</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.3}</td>\n",
       "      <td>0.990699</td>\n",
       "      <td>0.993304</td>\n",
       "      <td>0.992293</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999112</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.6}</td>\n",
       "      <td>0.983817</td>\n",
       "      <td>0.990513</td>\n",
       "      <td>0.990414</td>\n",
       "      <td>0.988243</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035503</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.9}</td>\n",
       "      <td>0.992001</td>\n",
       "      <td>0.993676</td>\n",
       "      <td>0.985338</td>\n",
       "      <td>0.990349</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.037205      0.005980         0.004524        0.000076   \n",
       "1       0.046634      0.004214         0.004865        0.000701   \n",
       "2       0.044932      0.001490         0.004472        0.000018   \n",
       "3       0.030735      0.000390         0.004408        0.000146   \n",
       "4       0.034019      0.000282         0.004352        0.000050   \n",
       "5       0.035503      0.000670         0.004385        0.000059   \n",
       "\n",
       "  param_learning_rate param_subsample  \\\n",
       "0                 0.2             0.3   \n",
       "1                 0.2             0.6   \n",
       "2                 0.2             0.9   \n",
       "3                 0.6             0.3   \n",
       "4                 0.6             0.6   \n",
       "5                 0.6             0.9   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.2, 'subsample': 0.3}           0.993118   \n",
       "1  {'learning_rate': 0.2, 'subsample': 0.6}           0.992746   \n",
       "2  {'learning_rate': 0.2, 'subsample': 0.9}           0.992374   \n",
       "3  {'learning_rate': 0.6, 'subsample': 0.3}           0.990699   \n",
       "4  {'learning_rate': 0.6, 'subsample': 0.6}           0.983817   \n",
       "5  {'learning_rate': 0.6, 'subsample': 0.9}           0.992001   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.989583           0.993045         0.991913        0.001650   \n",
       "1           0.994048           0.992293         0.993030        0.000744   \n",
       "2           0.992188           0.990226         0.991599        0.000971   \n",
       "3           0.993304           0.992293         0.992098        0.001073   \n",
       "4           0.990513           0.990414         0.988243        0.003135   \n",
       "5           0.993676           0.985338         0.990349        0.003597   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                3            0.999252            0.999907   \n",
       "1                1            1.000000            1.000000   \n",
       "2                4            1.000000            1.000000   \n",
       "3                2            0.999112            0.999907   \n",
       "4                6            1.000000            1.000000   \n",
       "5                5            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.999395          0.999518         0.000281  \n",
       "1            1.000000          1.000000         0.000000  \n",
       "2            1.000000          1.000000         0.000000  \n",
       "3            0.999860          0.999626         0.000364  \n",
       "4            1.000000          1.000000         0.000000  \n",
       "5            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_learning_rate', 'param_subsample', 'params', 'split0_test_score',\n",
       "       'split1_test_score', 'split2_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'mean_train_score',\n",
       "       'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.037205</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.3}</td>\n",
       "      <td>0.993118</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.993045</td>\n",
       "      <td>0.991913</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.046634</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.6}</td>\n",
       "      <td>0.992746</td>\n",
       "      <td>0.994048</td>\n",
       "      <td>0.992293</td>\n",
       "      <td>0.993030</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'learning_rate': 0.2, 'subsample': 0.9}</td>\n",
       "      <td>0.992374</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.990226</td>\n",
       "      <td>0.991599</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.030735</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.3}</td>\n",
       "      <td>0.990699</td>\n",
       "      <td>0.993304</td>\n",
       "      <td>0.992293</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999112</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.999626</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'learning_rate': 0.6, 'subsample': 0.6}</td>\n",
       "      <td>0.983817</td>\n",
       "      <td>0.990513</td>\n",
       "      <td>0.990414</td>\n",
       "      <td>0.988243</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.037205      0.005980         0.004524        0.000076   \n",
       "1       0.046634      0.004214         0.004865        0.000701   \n",
       "2       0.044932      0.001490         0.004472        0.000018   \n",
       "3       0.030735      0.000390         0.004408        0.000146   \n",
       "4       0.034019      0.000282         0.004352        0.000050   \n",
       "\n",
       "   param_learning_rate  param_subsample  \\\n",
       "0                  0.2              0.3   \n",
       "1                  0.2              0.6   \n",
       "2                  0.2              0.9   \n",
       "3                  0.6              0.3   \n",
       "4                  0.6              0.6   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.2, 'subsample': 0.3}           0.993118   \n",
       "1  {'learning_rate': 0.2, 'subsample': 0.6}           0.992746   \n",
       "2  {'learning_rate': 0.2, 'subsample': 0.9}           0.992374   \n",
       "3  {'learning_rate': 0.6, 'subsample': 0.3}           0.990699   \n",
       "4  {'learning_rate': 0.6, 'subsample': 0.6}           0.983817   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.989583           0.993045         0.991913        0.001650   \n",
       "1           0.994048           0.992293         0.993030        0.000744   \n",
       "2           0.992188           0.990226         0.991599        0.000971   \n",
       "3           0.993304           0.992293         0.992098        0.001073   \n",
       "4           0.990513           0.990414         0.988243        0.003135   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                3            0.999252            0.999907   \n",
       "1                1            1.000000            1.000000   \n",
       "2                4            1.000000            1.000000   \n",
       "3                2            0.999112            0.999907   \n",
       "4                6            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.999395          0.999518         0.000281  \n",
       "1            1.000000          1.000000         0.000000  \n",
       "2            1.000000          1.000000         0.000000  \n",
       "3            0.999860          0.999626         0.000364  \n",
       "4            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert parameters to int for plotting on x-axis\n",
    "cv_results['param_learning_rate'] = cv_results['param_learning_rate'].astype('float')\n",
    "cv_results['param_subsample'] = cv_results['param_subsample'].astype('float')\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]} \n",
    "\n",
    "\n",
    "for n, subsample in enumerate(param_grid['subsample']):\n",
    "    \n",
    "\n",
    "    # subplot 1/n\n",
    "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
    "    df = cv_results[cv_results['param_subsample']==subsample]\n",
    "\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
    "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
    "    plt.xlabel('learning_rate')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(\"subsample={0}\".format(subsample))\n",
    "    plt.ylim([0.60, 1])\n",
    "    plt.legend(['test score', 'train score'], loc='upper left')\n",
    "    plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:45:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { params } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic',\n",
       "              params={'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 200,\n",
       "                      'objective': 'binary:logistic', 'subsample': 0.3},\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chosen hyperparameters\n",
    "# 'objective':'binary:logistic' outputs probability rather than label, which we need for auc\n",
    "params = {'learning_rate': 0.2,\n",
    "          'max_depth': 2, \n",
    "          'n_estimators':200,\n",
    "          'subsample':0.3,\n",
    "         'objective':'binary:logistic'}\n",
    "\n",
    "# fit model on training data\n",
    "model = XGBClassifier(params = params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6572901e-01, 7.3427099e-01],\n",
       "       [9.4488502e-01, 5.5114970e-02],\n",
       "       [4.0281475e-02, 9.5971853e-01],\n",
       "       [2.6363134e-04, 9.9973637e-01],\n",
       "       [9.9976140e-01, 2.3858515e-04],\n",
       "       [4.1526252e-01, 5.8473748e-01],\n",
       "       [9.9953270e-01, 4.6730309e-04],\n",
       "       [9.9977183e-01, 2.2817185e-04],\n",
       "       [5.1581860e-04, 9.9948418e-01],\n",
       "       [9.9981755e-01, 1.8242068e-04]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.987987012987013"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc_auc\n",
    "from sklearn import metrics\n",
    "auc = metrics.roc_auc_score(y_test, y_pred[:, 1])\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'radius_mean': 0.0,\n",
       " 'texture_mean': 0.019771462,\n",
       " 'perimeter_mean': 0.0050336393,\n",
       " 'area_mean': 0.006757486,\n",
       " 'smoothness_mean': 0.0031501192,\n",
       " 'compactness_mean': 0.0017390844,\n",
       " 'concavity_mean': 0.0027090798,\n",
       " 'points_mean': 0.053792104,\n",
       " 'symmetry_mean': 0.0015510144,\n",
       " 'dimension_mean': 0.0056837904,\n",
       " 'radius_se': 0.009380138,\n",
       " 'texture_se': 0.0040931082,\n",
       " 'perimeter_se': 0.0,\n",
       " 'area_se': 0.007817217,\n",
       " 'smoothness_se': 0.008428129,\n",
       " 'compactness_se': 0.0012023861,\n",
       " 'concavity_se': 0.0,\n",
       " 'points_se': 0.0013081712,\n",
       " 'symmetry_se': 0.0040655895,\n",
       " 'dimension_se': 0.0,\n",
       " 'radius_worst': 0.6747759,\n",
       " 'texture_worst': 0.004109848,\n",
       " 'perimeter_worst': 0.0739764,\n",
       " 'area_worst': 0.010173431,\n",
       " 'smoothness_worst': 0.0044069225,\n",
       " 'compactness_worst': 0.0,\n",
       " 'concavity_worst': 0.02062731,\n",
       " 'points_worst': 0.060455296,\n",
       " 'symmetry_worst': 0.0035000218,\n",
       " 'dimension_worst': 0.011492409}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance\n",
    "importance = dict(zip(X_train.columns, model.feature_importances_))\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - With Random Forest classifier Accuracy of our model is 92% \n",
    "    - With Adaboosting the accuracy of the model is 98.9%\n",
    "    - With XGBoosting the accuracy of the model is 98.7%\n",
    "    - Most important feature is `radius_worst`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
